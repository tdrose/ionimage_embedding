{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc86b1d-3516-4a93-b3a5-e56d7804506f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "\n",
    "from metaspace import SMInstance\n",
    "\n",
    "import torch.nn.functional as functional\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import lightning.pytorch as pl\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from ionimage_embedding.dataloader.clr_dataloader import get_clr_dataloader\n",
    "from ionimage_embedding.models.clr.cae import CAE\n",
    "from ionimage_embedding.models.clr.clr_model import CLRmodel\n",
    "from ionimage_embedding.models.clr.pseudo_labeling import run_knn, string_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8813b5c3-7c6c-436a-bbb3-d1c9dd1c15b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(evaluation_datasets, testing_dsid, training_dsid):\n",
    "    training_results = {}\n",
    "    training_images = {}\n",
    "    training_if = {}\n",
    "    polarity = '+'\n",
    "\n",
    "    sm = SMInstance()\n",
    "\n",
    "    for k in evaluation_datasets:\n",
    "        ds = sm.dataset(id=k)\n",
    "        results = ds.results(database=(\"HMDB\", \"v4\"), fdr=0.2).reset_index()\n",
    "        training_results[k] = results\n",
    "        tmp = ds.all_annotation_images(fdr=0.2, database=(\"HMDB\", \"v4\"), only_first_isotope=True)\n",
    "        onsample = dict(zip(results['formula'].str.cat(results['adduct']), ~results['offSample']))\n",
    "        formula = [x.formula+x.adduct for x in tmp if onsample[x.formula+x.adduct]]\n",
    "        tmp = np.array([x._images[0] for x in tmp if onsample[x.formula+x.adduct]])\n",
    "        training_images[k] = tmp\n",
    "        training_if[k] = formula\n",
    "\n",
    "    padding_images = size_adaption_symmetric(training_images)\n",
    "\n",
    "    training_data = []\n",
    "    training_datasets = [] \n",
    "    training_ions = []\n",
    "\n",
    "    testing_data = []\n",
    "    testing_datasets = [] \n",
    "    testing_ions = []\n",
    "\n",
    "\n",
    "    for dsid, imgs in padding_images.items():\n",
    "\n",
    "        if dsid in training_dsid:\n",
    "            training_data.append(imgs)\n",
    "            training_datasets += [dsid] * imgs.shape[0]\n",
    "            training_ions += training_if[dsid]\n",
    "\n",
    "        testing_data.append(imgs)\n",
    "        testing_datasets += [dsid] * imgs.shape[0]\n",
    "        testing_ions += training_if[dsid]\n",
    "\n",
    "\n",
    "    training_data = np.concatenate(training_data)\n",
    "    training_datasets = np.array(training_datasets)\n",
    "    training_ions = np.array(training_ions)\n",
    "\n",
    "    testing_data = np.concatenate(testing_data)\n",
    "    testing_datasets = np.array(testing_datasets)\n",
    "    testing_ions = np.array(testing_ions)\n",
    "    \n",
    "    return training_data, training_datasets, training_ions, testing_data, testing_datasets, testing_ions\n",
    "\n",
    "\n",
    "def load_data(cache=False, cache_folder='/scratch/model_testing'):\n",
    "    evaluation_datasets = [\n",
    "    '2022-12-07_02h13m50s',\n",
    "    '2022-12-07_02h13m20s',\n",
    "    '2022-12-07_02h10m45s',\n",
    "    '2022-12-07_02h09m41s',\n",
    "    '2022-12-07_02h08m52s',\n",
    "    '2022-12-07_01h02m53s',\n",
    "    '2022-12-07_01h01m06s',\n",
    "    '2022-11-28_22h24m25s',\n",
    "    '2022-11-28_22h23m30s'\n",
    "                  ]\n",
    "    \n",
    "    training_dsid = evaluation_datasets[:len(evaluation_datasets)-1]\n",
    "    testing_dsid = evaluation_datasets[len(evaluation_datasets)-1]\n",
    "    \n",
    "    if cache:\n",
    "        # make hash of datasets\n",
    "        cache_file = 'clr_{}.pickle'.format(''.join(evaluation_datasets))\n",
    "        \n",
    "        # Check if cache folder exists\n",
    "        if not os.path.isdir(cache_folder):\n",
    "            os.mkdir(cache_folder)\n",
    "        \n",
    "        # Download data if it does not exist\n",
    "        if cache_file not in os.listdir(cache_folder):\n",
    "            data = download_data(evaluation_datasets, testing_dsid, training_dsid)\n",
    "            pickle.dump(data, open(os.path.join(cache_folder, cache_file), \"wb\"))\n",
    "            print('Saved file: {}'.format(os.path.join(cache_folder, cache_file)))\n",
    "            return data        \n",
    "        # Load cached data\n",
    "        else:\n",
    "            print('Loading cached data from: {}'.format(os.path.join(cache_folder, cache_file)))\n",
    "            return pickle.load(open(os.path.join(cache_folder, cache_file), \"rb\" ) )\n",
    "    \n",
    "    else:\n",
    "        return download_data(evaluation_datasets, testing_dsid, training_dsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb100ddc-9bf0-4a1d-ae8e-f66abeee9b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached data from: /scratch/model_testing/clr_2022-12-07_02h13m50s2022-12-07_02h13m20s2022-12-07_02h10m45s2022-12-07_02h09m41s2022-12-07_02h08m52s2022-12-07_01h02m53s2022-12-07_01h01m06s2022-11-28_22h24m25s2022-11-28_22h23m30s.pickle\n"
     ]
    }
   ],
   "source": [
    "training_data, training_datasets, training_ions, testing_data, testing_datasets, testing_ions = load_data(cache=True, cache_folder='/scratch/model_testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a00ab32-3f1d-430e-a2a2-965d3d498bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Image normalization\n",
    "sampleN = len(training_data)\n",
    "val_data_fraction = .3\n",
    "\n",
    "for i in range(0, sampleN):\n",
    "    current_min = np.min(training_data[i, ::])\n",
    "    current_max = np.max(training_data[i, ::])\n",
    "    training_data[i, ::] = (training_data[i, ::] - current_min) / (current_max - current_min)\n",
    "\n",
    "\n",
    "training_mask = np.arange(training_data.shape[0])\n",
    "val_mask = np.random.randint(training_data.shape[0], size=math.floor(training_data.shape[0] * val_data_fraction))\n",
    "training_mask = np.ones(len(training_data), bool)\n",
    "training_mask[val_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96bbc8e7-6acf-4f37-931a-b8ec5e8a961e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_encoder = preprocessing.LabelEncoder()\n",
    "dsl_int = torch.tensor(ds_encoder.fit_transform(training_datasets))\n",
    "il_encoder = preprocessing.LabelEncoder()\n",
    "ill_int = torch.tensor(il_encoder.fit_transform(training_ions))\n",
    "height = training_data.shape[1]\n",
    "width = training_data.shape[2]\n",
    "sampleN = len(training_data)\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01bc1ab1-3c5b-4e10-aabe-fad51622f516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdl = get_clr_dataloader(images=training_data[training_mask],\n",
    "                   dataset_labels=dsl_int[training_mask],\n",
    "                   ion_labels=ill_int[training_mask],\n",
    "                   height=height,\n",
    "                   width=width,\n",
    "                   index=np.arange(training_data.shape[0])[training_mask],\n",
    "                   # Rotate images\n",
    "                   transform=transforms.RandomRotation(degrees=(0, 360)),\n",
    "                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5e21e8d-d895-4c24-8861-97b99ef56b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vdl = get_clr_dataloader(images=training_data[val_mask],\n",
    "                   dataset_labels=dsl_int[val_mask],\n",
    "                   ion_labels=ill_int[val_mask],\n",
    "                   height=height,\n",
    "                   width=width,\n",
    "                   index=np.arange(training_data.shape[0])[val_mask],\n",
    "                   # Rotate images\n",
    "                   transform=transforms.RandomRotation(degrees=(0, 360)),\n",
    "                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebaf0d0-9e68-45a9-9ce4-24db229cb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_image, dl_sample_id, dl_dataset_label, dl_ion_label = next(iter(tdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c1fece5-8912-4bad-9e4e-d1be182c68d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl_image, dl_sample_id, dl_dataset_label, dl_ion_label = next(iter(vdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98678eb9-16cf-4b82-8261-8be4e0f1536b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6],\n",
       "        [1],\n",
       "        [6],\n",
       "        [5],\n",
       "        [4],\n",
       "        [6],\n",
       "        [0],\n",
       "        [5],\n",
       "        [6],\n",
       "        [1],\n",
       "        [3],\n",
       "        [5],\n",
       "        [2],\n",
       "        [6],\n",
       "        [1],\n",
       "        [3],\n",
       "        [7],\n",
       "        [3],\n",
       "        [5],\n",
       "        [4],\n",
       "        [1],\n",
       "        [6],\n",
       "        [7],\n",
       "        [0],\n",
       "        [6],\n",
       "        [4],\n",
       "        [0],\n",
       "        [3],\n",
       "        [3],\n",
       "        [7],\n",
       "        [2],\n",
       "        [4],\n",
       "        [4],\n",
       "        [1],\n",
       "        [1],\n",
       "        [5],\n",
       "        [6],\n",
       "        [5],\n",
       "        [3],\n",
       "        [7],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [6],\n",
       "        [4],\n",
       "        [1],\n",
       "        [4],\n",
       "        [6],\n",
       "        [3],\n",
       "        [4],\n",
       "        [4],\n",
       "        [7],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [7],\n",
       "        [3],\n",
       "        [4],\n",
       "        [4],\n",
       "        [0],\n",
       "        [3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [2],\n",
       "        [2],\n",
       "        [5],\n",
       "        [3],\n",
       "        [2],\n",
       "        [5],\n",
       "        [0],\n",
       "        [0],\n",
       "        [3],\n",
       "        [0],\n",
       "        [6],\n",
       "        [4],\n",
       "        [0],\n",
       "        [3],\n",
       "        [0],\n",
       "        [7],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [7],\n",
       "        [2],\n",
       "        [5],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [4],\n",
       "        [2],\n",
       "        [3],\n",
       "        [6],\n",
       "        [5],\n",
       "        [3],\n",
       "        [5],\n",
       "        [6],\n",
       "        [0],\n",
       "        [1],\n",
       "        [4],\n",
       "        [7],\n",
       "        [7],\n",
       "        [1],\n",
       "        [6],\n",
       "        [5],\n",
       "        [0],\n",
       "        [0],\n",
       "        [7],\n",
       "        [3],\n",
       "        [5],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [7],\n",
       "        [2],\n",
       "        [6],\n",
       "        [5],\n",
       "        [7],\n",
       "        [6],\n",
       "        [0],\n",
       "        [5],\n",
       "        [6],\n",
       "        [3],\n",
       "        [3],\n",
       "        [5],\n",
       "        [5]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d028e-2051-4ce2-b89c-aa5053fdb367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpuCUDA12",
   "language": "python",
   "name": "torch-gpucuda12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
